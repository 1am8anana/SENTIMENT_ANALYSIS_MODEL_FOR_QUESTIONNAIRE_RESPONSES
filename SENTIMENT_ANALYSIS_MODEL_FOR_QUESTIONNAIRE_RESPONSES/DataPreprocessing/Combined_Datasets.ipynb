{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas library to manage/organize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Combining 3 Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* tcas61.csv\n",
    "* review_shopping.csv\n",
    "* general-amy.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "before that we need to create a split_tap function that can handle space between sentences and labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_tap(df, feature, label, exist_col):\n",
    "    df[feature] = df[exist_col].str.split(pat='\\t').str[0]\n",
    "    df[label] = df[exist_col].str.split(pat='\\t').str[1]\n",
    "    df.drop(columns=[exist_col], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset path taht we have gathered from PyThaiNLP on local.\n",
    "data_paths = ['../Dataset/tcas61.csv', '../Dataset/review_shopping.csv', '../Dataset/general-amy.csv']\n",
    "\n",
    "dataset = []\n",
    "# loop through all data_paths taht we have\n",
    "for data_path in data_paths:\n",
    "    data = pd.read_csv(data_path)\n",
    "    # And then use split_tap function that we have created before, to split sentences and labelling.\n",
    "    data = split_tap(data, 'sentence', 'labelling', 'sentences')\n",
    "    # Now we need to label the individual sentence that ready and easily through the other process. \n",
    "    data['label'] = data['labelling'].map({'pos':0, 'neg':1})\n",
    "    # Append/Add the data prepared to the lsit\n",
    "    dataset.append(data)\n",
    "\n",
    "# This line of code is will integrate/combined all the data into one dataframe.\n",
    "datasets = pd.concat(dataset, ignore_index=True)\n",
    "X = datasets['sentence']\n",
    "y = datasets['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Explore some information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see some information about feature in this case is 'sentences'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 342 entries, 0 to 341\n",
      "Series name: sentence\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "342 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 2.8+ KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this information about target/label of each sentence, Now we can see our target data feels like balance of each class (Negative and Positive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    194\n",
       "0    148\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and this is overall onformation about teh datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 342 entries, 0 to 341\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   sentence   342 non-null    object\n",
      " 1   labelling  342 non-null    object\n",
      " 2   label      342 non-null    int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 8.1+ KB\n"
     ]
    }
   ],
   "source": [
    "datasets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Export datarame to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.to_csv('..\\Dataset\\datasets.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
